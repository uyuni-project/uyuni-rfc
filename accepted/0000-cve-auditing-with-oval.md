- Feature Name: CVE Auditing with OVAL
- Start Date: 2023-06-10

# Summary
Use OVAL *(Open Vulnerability and Assessment Language)* data instead of channels data to conduct CVE auditing.

# Motivation

Uyuni performs CVE auditing though channels, which presents a range of issues. One problem is that the channels data is extremely large in size. This is a problem because the CVE auditing feature only requires a small amount of that data to function. However, users still have to wait for the channels to sync before they can audit systems. Additionally, the accuracy of CVE auditing through channels is not consistently reliable. To illustrate this, consider the scenario where you audit a system that has a vulnerability that hasn't been patched yet. In such cases, Uyuni would provide an incorrect assessment, indicating that the system is 'Not affected', despite it being vulnerable to the unpatched vulnerability.

The motivation behind this RFC is to highlight that CVE auditing doesn't require all the data contained in channels. We aim to develop a better approach that produces completely accurate audits without false negatives, which can occur with the current implementation.

# Detailed design

The diagram at *figure. 1* shows the oval module, its components and where it would be placed in Uyuni's architecture. In the following sections I will explain in more details the responsibility of each component, in addition, to the integration points with Uyuni.

|             ![](https://svgshare.com/i/rRo.svg)              |
| :----------------------------------------------------------: |
| ***Figure 1: High-level architecture diagram of the proposed solution*** |

### OVAL Parser

The oval parser is responsible mainly for the  translation of oval files from XML to a more usable POJO representation. We can extend the parser responsibility to catch and report errors, but since the oval files come from trusted sources, it won't be necessary.

As OVAL files are structured in XML, we don't need to write the parser from scratch and can use an existing XML parsing library. The decision of choosing the XML parsing library is being tracked in [uyuni#7108](https://github.com/uyuni-project/uyuni/issues/7108).

Given that Java is a statically typed language, oval types need to be defined before they can be used. While this adds some overhead when getting started with implementation, because the oval standard defines an enormous number of types, we can use a XML-to-POJO generator tool that generates Java classes from XML schemas .e.g **xjc**. The quality of the generated code might not be of the quality that we want but it should provide a good starting point from which we can continue and improve.

It's crucial to state that the Linux OVAL files don't use all of the features defined in the OVAL specification. So, the parser is only required to support the subset of features used in the Linux OVAL files. Nevertheless, the unsupported features should be documented to prevent confusion.

|             ![](https://svgshare.com/i/rPf.svg)              |
| :----------------------------------------------------------: |
| ***Figure 2. A simplified class diagram of the parser component.*** |

#### OVAL Extensions Support

The primary objective of the OVAL parser component is to parse openSUSE and other Linux-based distributions OVAL files. This requires that we add support to the Linux OVAL extension. We can take it a step further and offer an abstraction that can be used to implement other extensions. This should, for example, facilitate the integration with Android[^5] and Windows[^6] clients when they become supported in Uyuni.

### OVAL Downloader

The OVAL Downloader is responsible for finding OVAL documents online, downloading them, and caching them for easy access. However, since the relevant OVAL data is saved in PostgreSQL, it is possible for the downloader to skip caching the OVAL files or remove them once they are stored in the database. This approach would reduce the amount of storage needed.

OVAL data comes from several  sources – OvalRepo, OpenSUSE OVAL repository and other Linux distributions repositories – which means that the OVAL Downloader needs to be robust in the presence of errors. It is essential also that the component is designed with comprehensive error messaging to provide instant alerts in case an OVAL source is moved or the server is down.

### OVAL DAO

The OVAL DAO provides a unified interface of all the operations that can be applied on the OVAL data. It is the only way to query or modify the OVAL data from the Uyuni database. Because there are at least two different patterns for accessing the database *(XML Named queries and JPA Criteria API)* within Uyuni codebase, I thought using a DAO would be a good idea in case I changed my mind about which data-access pattern to use later. 

This component will allow me to do two main things that would otherwise be extremely difficult to implement:

- Testing OVAL data before doing the integration with Uyuni
- Creating mock DAOs for testing

As a starter, the DAO will provide the following methods:

```java
public interface OvalDAO {
    List<Product> getAffectedProducts(String cve);
    CVEPatchStatus getCVEPatchStatus(String cve);
    boolean isProductAffected(Product product, String cve);
    void storeOvalData(OvalRoot root);
    Optional<CVSS> getCVSS(String cveIdentifier);
}
```

### Database Storage for OVAL Documents

Once the OVAL document is parsed, the next step is to store it in a database. A relational database, such as PostgreSQL, seems like an obvious choice for the following reasons: 

- Uyuni uses PostgreSQL
- A relational database enable us to query OVAL data with SQL

To speedup the development, I plan to use an ORM*(Object-relational mapping)* framework so I can auto-generate database tables from Java objects/entities. Since Hibernate is already used inside Uyuni and I have experience using it, it seems to be the obvious choice.

Skimming over Uyuni' codebase, I noticed two approaches being used to query the database: XML-based Named queries and JPA Criteria API. I'm not familiar with either approaches, but I'm willing to learn or use the more modern methods that I'm familiar with: JPA repositories, JPA projections and annotation-based Named queries. The decision will depend on how hard this would make the integration with Uyuni's code later.

#### Storing Criteria Tree

The *CriteriaType* defines the structure of a logical statement that combines other logical statements. This construct is used to combine references to OVAL Tests, OVAL Definitions, and other *CriteriaTypes* into one logical statement[^3].  Because *CriteriaType* can reference multiple *CriteriaTypes*, it is by definition a tree. This is a problem because relational databases are not so great at storing trees.

Relational databases are fantastic at storing tabular data, where some data relates to other data. However, when the relationship points back to the same table a.k.a Trees, it gets complicated. 

Luckily, There are multiple patterns used to store trees in a relational database[^1]:

- **JSON Blob**

  The easiest way to achieve this is to forgo the relational database and store the structure in a JSON blob. This lets us ignore the complexity of reading and writing across many records and just store everything as a single record. We would then do any parsing and updating in our application code instead of our database.

- **Storing Parent Keys**

  One way to achieve this is to store on every node the ID of its immediate parent. Nodes that don’t have a parent would then store *NULL*, and nodes with a parent can store a reference to that parent.

- **Closure Tables**

  We can use one other mechanism to store the graph separately from the nodes in what’s known as a Closure Table. This parallel table will store every ancestor for every node, including the distance between the node and its ancestor.

Thinking about it, I couldn't find any use cases that involves criteria and requires more than simple reading and writing of the criteria from/to the database. Thus, I'm leaning toward the JSON Blob solution because it's the simplest. 

To be honest, I haven't thought about this thorough. I think I can delay this decision to implementation, and by then I should have a broader view of the problem and pick the "best" solution.

## Integration with Uyuni

Once the database is ready, we can start the integration process with Uyuni. The integration will be done in 4 steps. But before that there are two problems that I need to solve before the integration:

### Distinguishing QA from Released patches

In the Open SUSE OVAL documents, patches in QA have `(in QA)` at the end of their title, while released patches don't. This pattern doesn't occur in the other distributions OVAL documents As far as I know, it is impossible to distinguish QA from Released for Linux distributions other than Open SUSE. Before starting the integration, I need to discuss (with my mentors) the possible solutions for this problem.

### Auditing Other Linux Distributions (beside Open SUSE)

With Open SUSE OVAL data in the database, checking if an Open SUSE Linux product is vulnerable to certain CVE is straight forward. However, there is a problem when dealing with other distributions. 

The problem is that not all supported distributions provide both the vulnerability and patch style OVAL documents. As shown the table below, 6 distributions provide both while the others only provide one or neither of them.

| Linux Distribution       | Patch-style OVAL | Vulnerability-style OVAL |
| ------------------------ | :--------------- | ------------------------ |
| Open SUSE Products       | ✔️                | ✔️                        |
| Ubuntu                   | ✔️                | ✔️                        |
| Debian                   | ✔️                | ✔️                        |
| AlmaLinux                | ✔️                | ❌                        |
| Oracle Linux             | ✔️                | ✔️                        |
| CentOS                   | ✔️                | ✔️                        |
| Red Hat Enterprise Linux | ✔️                | ✔️                        |
| Rocky Linux              | ✔️                | ❌                        |
| Alibaba Cloud Linux      | ❌                | ❌                        |
| Amazon Linux             | ❌                | ❌                        |

I got most of the OVAL data from the so called OVAL repository.[^10] Rocky Linux and AlmaLinux don't appear to be included in the OVAL data that was provided by the repository, but I was able to locate them elsewhere.

I have looked into how OVAL scanning tools[^8][^9] handle Linux distributions that don't provide OVAL data, and they use similar tricks to the channels Uyuni use. So, I propose we **keep using channels for the OVAL-less distributions, and use OVAL data for the OVAL-full distributions**.

# Drawbacks

# Alternatives

# Unresolved questions
